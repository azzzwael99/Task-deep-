{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNP5rv0SVlOYCauzKVBrh+O"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Obf0MR95bt9L","executionInfo":{"status":"ok","timestamp":1742556587442,"user_tz":-120,"elapsed":533195,"user":{"displayName":"Azza abdelaziz","userId":"08770813708774899615"}},"outputId":"5656446d-c379-47b1-9819-e066b330dd50"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading from https://www.kaggle.com/api/v1/datasets/download/ismailnasri20/driver-drowsiness-dataset-ddd?dataset_version_number=1...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 2.58G/2.58G [00:28<00:00, 96.3MB/s]"]},{"output_type":"stream","name":"stdout","text":["Extracting files...\n"]},{"output_type":"stream","name":"stderr","text":["\n"]},{"output_type":"stream","name":"stdout","text":["Files and folders in data_path: ['Drowsy', 'Non Drowsy']\n","Data shape after loading: (41793, 1, 32, 32, 3) (41793,)\n","Data successfully split!\n","Training samples: 33434\n","Testing samples: 8359\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(**kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","\u001b[1m4180/4180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 19ms/step - accuracy: 0.9008 - loss: 0.1969 - val_accuracy: 0.9983 - val_loss: 0.0065\n","Epoch 2/3\n","\u001b[1m4180/4180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 19ms/step - accuracy: 0.9957 - loss: 0.0138 - val_accuracy: 0.9995 - val_loss: 0.0017\n","Epoch 3/3\n","\u001b[1m4180/4180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 18ms/step - accuracy: 0.9990 - loss: 0.0040 - val_accuracy: 0.9999 - val_loss: 5.6625e-04\n","\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 14ms/step - accuracy: 0.9997 - loss: 0.0011\n","Test accuracy: 1.00\n"]}],"source":["import os\n","import numpy as np\n","import cv2\n","from sklearn.model_selection import train_test_split\n","import kagglehub\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, TimeDistributed, Dropout\n","\n","# 1. تنزيل مجموعة البيانات من KaggleHub\n","dataset_path = kagglehub.dataset_download(\"ismailnasri20/driver-drowsiness-dataset-ddd\")\n","\n","# 2. تحديد مسار البيانات الصحيح\n","data_path = os.path.join(dataset_path, \"Driver Drowsiness Dataset (DDD)\")\n","\n","# 3. التحقق من وجود مسار البيانات\n","if not os.path.exists(data_path):\n","    raise FileNotFoundError(f\"Path {data_path} not found!\")\n","\n","print(\"Files and folders in data_path:\", os.listdir(data_path))\n","\n","# 4. تحديث أسماء الفئات لمطابقة أسماء المجلدات الفعلية\n","classes = [\"Drowsy\", \"Non Drowsy\"]\n","class_mapping = {\"Drowsy\": 1, \"Non Drowsy\": 0}  # 1 = Drowsy, 0 = Awake\n","\n","# 5. تقليل عدد الإطارات المستخرجة من كل فيديو\n","frame_skip = 10\n","\n","# 6. تقليل حجم الصورة\n","img_size = (32, 32)\n","\n","# 7. دالة استخراج الإطارات من الفيديو\n","def extract_frames(video_path, frame_skip=frame_skip):\n","    frames = []\n","    cap = cv2.VideoCapture(video_path)\n","\n","    if not cap.isOpened():\n","        print(f\"Error: Unable to open video {video_path}\")\n","        return frames\n","\n","    frame_count = 0\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        if frame_count % frame_skip == 0:\n","            frame = cv2.resize(frame, img_size) / 255.0  # تصغير وتطبيع الصورة\n","            frames.append(frame)\n","\n","        frame_count += 1\n","\n","    cap.release()\n","    return frames\n","\n","# 8. دالة تحميل بيانات الفيديو\n","def load_video_data(data_path):\n","    X, y = [], []\n","\n","    for class_name in classes:\n","        class_path = os.path.join(data_path, class_name)\n","        if not os.path.exists(class_path):\n","            print(f\"Warning: Folder {class_name} not found, skipping...\")\n","            continue\n","\n","        for video_name in os.listdir(class_path):\n","            video_path = os.path.join(class_path, video_name)\n","            frames = extract_frames(video_path, frame_skip)\n","\n","            if not frames:\n","                print(f\"Warning: No frames extracted from {video_path}\")\n","                continue\n","\n","            X.append(frames)\n","            y.append(class_mapping[class_name])\n","\n","    return np.array(X), np.array(y)\n","\n","# 9. تحميل مجموعة البيانات\n","X, y = load_video_data(data_path)\n","\n","# 10. التحقق من حجم البيانات\n","if X.shape[0] == 0:\n","    raise ValueError(\"No data found! Check the dataset path and files.\")\n","\n","print(\"Data shape after loading:\", X.shape, y.shape)\n","\n","# 11. تقسيم البيانات إلى مجموعة تدريب واختبار\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(\"Data successfully split!\")\n","print(\"Training samples:\", X_train.shape[0])\n","print(\"Testing samples:\", X_test.shape[0])\n","\n","# 12. التحقق من عدم فراغ مجموعة التدريب\n","if len(X_train) == 0 or len(y_train) == 0:\n","    raise ValueError(\"Insufficient training data!\")\n","\n","# 13. بناء نموذج CNN-LSTM محسن\n","model = Sequential([\n","    TimeDistributed(Conv2D(16, (3,3), activation='relu', padding='same'), input_shape=(10, 32, 32, 3)),\n","    TimeDistributed(MaxPooling2D((2,2))),\n","    TimeDistributed(Conv2D(32, (3,3), activation='relu', padding='same')),\n","    TimeDistributed(MaxPooling2D((2,2))),\n","    TimeDistributed(Flatten()),\n","\n","    LSTM(32, return_sequences=True),\n","    LSTM(16),\n","    Dropout(0.3),\n","    Dense(16, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","# 14. تجميع النموذج\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","# 15. تقليل عدد الإيبوك وحجم الـ Batch\n","epochs = 3\n","batch_size = 8\n","\n","# 16. تدريب النموذج\n","history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n","\n","# 17. تقييم النموذج\n","loss, acc = model.evaluate(X_test, y_test)\n","print(f\"Test accuracy: {acc:.2f}\")"]}]}