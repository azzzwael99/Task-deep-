{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b788841f",
   "metadata": {},
   "source": [
    "# **CNN-LSTM for Image-Based Human Action Recognition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bdcf58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# تحديد مسار البيانات\n",
    "dataset_path = \"path_to_downloaded_data\"  # استبدل بالمسار الفعلي\n",
    "\n",
    "# فحص محتويات مجلد البيانات\n",
    "print(os.listdir(dataset_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83cc0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# تحميل البيانات باستخدام image_dataset_from_directory\n",
    "batch_size = 32\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "\n",
    "train_dir = os.path.join(dataset_path, \"train\")\n",
    "val_dir = os.path.join(dataset_path, \"val\")\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    seed=123,\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size)\n",
    "\n",
    "# الحصول على أسماء التصنيفات\n",
    "class_names = train_ds.class_names\n",
    "print(\"Classes:\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2793297",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# بناء نموذج CNN-LSTM\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Flatten(),\n",
    "    layers.Reshape((1, -1)),  # تحويل الإخراج لإدخاله إلى LSTM\n",
    "    layers.LSTM(128, return_sequences=True),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(len(class_names), activation='softmax')  # عدد الفئات\n",
    "])\n",
    "\n",
    "# طباعة ملخص النموذج\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bcd8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# تجميع النموذج\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# تدريب النموذج\n",
    "epochs = 10\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs)\n",
    "\n",
    "# حفظ النموذج\n",
    "model.save(\"human_action_recognition.h5\")\n",
    "\n",
    "# رسم دقة التدريب\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}