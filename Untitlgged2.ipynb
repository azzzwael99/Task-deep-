{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPo3VHaEQ/VebaHmCjpFjY9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import os\n","import numpy as np\n","import cv2\n","from sklearn.model_selection import train_test_split\n","import kagglehub\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, LSTM, Dense, TimeDistributed, Dropout\n","\n","\n","dataset_path = kagglehub.dataset_download(\"ismailnasri20/driver-drowsiness-dataset-ddd\")\n","\n","\n","data_path = os.path.join(dataset_path, \"Driver Drowsiness Dataset (DDD)\")\n","\n","\n","if not os.path.exists(data_path):\n","    raise FileNotFoundError(f\"Path {data_path} not found!\")\n","\n","print(\"Files and folders in data_path:\", os.listdir(data_path))\n","\n","\n","classes = [\"Drowsy\", \"Non Drowsy\"]\n","class_mapping = {\"Drowsy\": 1, \"Non Drowsy\": 0}  # 1 = Drowsy, 0 = Awake\n","\n","frame_skip = 10\n","\n","\n","img_size = (32, 32)\n","\n","def extract_frames(video_path, frame_skip=frame_skip):\n","    frames = []\n","    cap = cv2.VideoCapture(video_path)\n","\n","    if not cap.isOpened():\n","        print(f\"Error: Unable to open video {video_path}\")\n","        return frames\n","\n","    frame_count = 0\n","    while True:\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        if frame_count % frame_skip == 0:\n","            frame = cv2.resize(frame, img_size) / 255.0  # تصغير وتطبيع الصورة\n","            frames.append(frame)\n","\n","        frame_count += 1\n","\n","    cap.release()\n","    return frames\n","\n","\n","def load_video_data(data_path):\n","    X, y = [], []\n","\n","    for class_name in classes:\n","        class_path = os.path.join(data_path, class_name)\n","        if not os.path.exists(class_path):\n","            print(f\"Warning: Folder {class_name} not found, skipping...\")\n","            continue\n","\n","        for video_name in os.listdir(class_path):\n","            video_path = os.path.join(class_path, video_name)\n","            frames = extract_frames(video_path, frame_skip)\n","\n","            if not frames:\n","                print(f\"Warning: No frames extracted from {video_path}\")\n","                continue\n","\n","            X.append(frames)\n","            y.append(class_mapping[class_name])\n","\n","    return np.array(X), np.array(y)\n","\n","\n","X, y = load_video_data(data_path)\n","\n","if X.shape[0] == 0:\n","    raise ValueError(\"No data found! Check the dataset path and files.\")\n","\n","print(\"Data shape after loading:\", X.shape, y.shape)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","print(\"Data successfully split!\")\n","print(\"Training samples:\", X_train.shape[0])\n","print(\"Testing samples:\", X_test.shape[0])\n","\n","if len(X_train) == 0 or len(y_train) == 0:\n","    raise ValueError(\"Insufficient training data!\")\n","\n","\n","model = Sequential([\n","    TimeDistributed(Conv2D(16, (3,3), activation='relu', padding='same'), input_shape=(10, 32, 32, 3)),\n","    TimeDistributed(MaxPooling2D((2,2))),\n","    TimeDistributed(Conv2D(32, (3,3), activation='relu', padding='same')),\n","    TimeDistributed(MaxPooling2D((2,2))),\n","    TimeDistributed(Flatten()),\n","\n","    LSTM(32, return_sequences=True),\n","    LSTM(16),\n","    Dropout(0.3),\n","    Dense(16, activation='relu'),\n","    Dense(1, activation='sigmoid')\n","])\n","\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","epochs = 3\n","batch_size = 8\n","\n","\n","history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n","\n","\n","loss, acc = model.evaluate(X_test, y_test)\n","print(f\"Test accuracy: {acc:.2f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"87kQjFuFkbsO","executionInfo":{"status":"ok","timestamp":1742558939515,"user_tz":-120,"elapsed":595889,"user":{"displayName":"Azza abdelaziz","userId":"08770813708774899615"}},"outputId":"f468552d-378f-4033-91f7-1a362823eaf1"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Files and folders in data_path: ['Drowsy', 'Non Drowsy']\n","Data shape after loading: (41793, 1, 32, 32, 3) (41793,)\n","Data successfully split!\n","Training samples: 33434\n","Testing samples: 8359\n","Epoch 1/3\n","\u001b[1m4180/4180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m91s\u001b[0m 20ms/step - accuracy: 0.9019 - loss: 0.2020 - val_accuracy: 0.9987 - val_loss: 0.0048\n","Epoch 2/3\n","\u001b[1m4180/4180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 20ms/step - accuracy: 0.9975 - loss: 0.0093 - val_accuracy: 0.9981 - val_loss: 0.0056\n","Epoch 3/3\n","\u001b[1m4180/4180\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 18ms/step - accuracy: 0.9985 - loss: 0.0059 - val_accuracy: 0.9951 - val_loss: 0.0139\n","\u001b[1m262/262\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 12ms/step - accuracy: 0.9951 - loss: 0.0148\n","Test accuracy: 1.00\n"]}]}]}